{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice              \n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "X.drop([\"Alley\", \"FireplaceQu\", \"PoolQC\", \"Fence\", \"MiscFeature\"], inplace=True, axis=1)\n",
    "X_test_full.drop([\"Alley\", \"FireplaceQu\", \"PoolQC\", \"Fence\", \"MiscFeature\"], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X.columns if X[cname].nunique() < 7 and X[cname].dtype == \"object\"]\n",
    "\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = numeric_cols + categorical_cols\n",
    "X = X[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\ncount  1460.000000  1201.000000    1460.000000  1460.000000  1460.000000   \nmean     56.897260    70.049958   10516.828082     6.099315     5.575342   \nstd      42.300571    24.284752    9981.264932     1.382997     1.112799   \nmin      20.000000    21.000000    1300.000000     1.000000     1.000000   \n25%      20.000000    59.000000    7553.500000     5.000000     5.000000   \n50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n75%      70.000000    80.000000   11601.500000     7.000000     6.000000   \nmax     190.000000   313.000000  215245.000000    10.000000     9.000000   \n\n         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\ncount  1460.000000   1460.000000  1452.000000  1460.000000  1460.000000  ...   \nmean   1971.267808   1984.865753   103.685262   443.639726    46.549315  ...   \nstd      30.202904     20.645407   181.066207   456.098091   161.319273  ...   \nmin    1872.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n25%    1954.000000   1967.000000     0.000000     0.000000     0.000000  ...   \n50%    1973.000000   1994.000000     0.000000   383.500000     0.000000  ...   \n75%    2000.000000   2004.000000   166.000000   712.250000     0.000000  ...   \nmax    2010.000000   2010.000000  1600.000000  5644.000000  1474.000000  ...   \n\n        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\ncount  1460.000000  1460.000000  1460.000000    1460.000000  1460.000000   \nmean    472.980137    94.244521    46.660274      21.954110     3.409589   \nstd     213.804841   125.338794    66.256028      61.119149    29.317331   \nmin       0.000000     0.000000     0.000000       0.000000     0.000000   \n25%     334.500000     0.000000     0.000000       0.000000     0.000000   \n50%     480.000000     0.000000    25.000000       0.000000     0.000000   \n75%     576.000000   168.000000    68.000000       0.000000     0.000000   \nmax    1418.000000   857.000000   547.000000     552.000000   508.000000   \n\n       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \ncount  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000  \nmean     15.060959     2.758904     43.489041     6.321918  2007.815753  \nstd      55.757415    40.177307    496.123024     2.703626     1.328095  \nmin       0.000000     0.000000      0.000000     1.000000  2006.000000  \n25%       0.000000     0.000000      0.000000     5.000000  2007.000000  \n50%       0.000000     0.000000      0.000000     6.000000  2008.000000  \n75%       0.000000     0.000000      0.000000     8.000000  2009.000000  \nmax     480.000000   738.000000  15500.000000    12.000000  2010.000000  \n\n[8 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1460.000000</td>\n      <td>1201.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1452.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>...</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>56.897260</td>\n      <td>70.049958</td>\n      <td>10516.828082</td>\n      <td>6.099315</td>\n      <td>5.575342</td>\n      <td>1971.267808</td>\n      <td>1984.865753</td>\n      <td>103.685262</td>\n      <td>443.639726</td>\n      <td>46.549315</td>\n      <td>...</td>\n      <td>472.980137</td>\n      <td>94.244521</td>\n      <td>46.660274</td>\n      <td>21.954110</td>\n      <td>3.409589</td>\n      <td>15.060959</td>\n      <td>2.758904</td>\n      <td>43.489041</td>\n      <td>6.321918</td>\n      <td>2007.815753</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>42.300571</td>\n      <td>24.284752</td>\n      <td>9981.264932</td>\n      <td>1.382997</td>\n      <td>1.112799</td>\n      <td>30.202904</td>\n      <td>20.645407</td>\n      <td>181.066207</td>\n      <td>456.098091</td>\n      <td>161.319273</td>\n      <td>...</td>\n      <td>213.804841</td>\n      <td>125.338794</td>\n      <td>66.256028</td>\n      <td>61.119149</td>\n      <td>29.317331</td>\n      <td>55.757415</td>\n      <td>40.177307</td>\n      <td>496.123024</td>\n      <td>2.703626</td>\n      <td>1.328095</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>20.000000</td>\n      <td>21.000000</td>\n      <td>1300.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1872.000000</td>\n      <td>1950.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2006.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>20.000000</td>\n      <td>59.000000</td>\n      <td>7553.500000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>1954.000000</td>\n      <td>1967.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>334.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>2007.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>50.000000</td>\n      <td>69.000000</td>\n      <td>9478.500000</td>\n      <td>6.000000</td>\n      <td>5.000000</td>\n      <td>1973.000000</td>\n      <td>1994.000000</td>\n      <td>0.000000</td>\n      <td>383.500000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>480.000000</td>\n      <td>0.000000</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>2008.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>70.000000</td>\n      <td>80.000000</td>\n      <td>11601.500000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>2000.000000</td>\n      <td>2004.000000</td>\n      <td>166.000000</td>\n      <td>712.250000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>576.000000</td>\n      <td>168.000000</td>\n      <td>68.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>2009.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>190.000000</td>\n      <td>313.000000</td>\n      <td>215245.000000</td>\n      <td>10.000000</td>\n      <td>9.000000</td>\n      <td>2010.000000</td>\n      <td>2010.000000</td>\n      <td>1600.000000</td>\n      <td>5644.000000</td>\n      <td>1474.000000</td>\n      <td>...</td>\n      <td>1418.000000</td>\n      <td>857.000000</td>\n      <td>547.000000</td>\n      <td>552.000000</td>\n      <td>508.000000</td>\n      <td>480.000000</td>\n      <td>738.000000</td>\n      <td>15500.000000</td>\n      <td>12.000000</td>\n      <td>2010.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN = X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    \n",
    "                           ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                           ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    " ])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(preprocessor.fit_transform(X))\n",
    "X_test_final = pd.DataFrame(preprocessor.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-913e3b388ad9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mselector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodelo\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m107\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mcolumnasfinales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\agusentorno\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\agusentorno\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# Get coefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\agusentorno\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    546\u001b[0m                               \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\agusentorno\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\agusentorno\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\agusentorno\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1159\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "modelo = XGBRegressor(objective='reg:squarederror', eval_metric='mae', random_state=0, \n",
    "    n_estimators= 550, learning_rate = 0.0495, n_jobs=2, colsample_bytree=0.3, subsample=0.6, verbosity=1)# Your code here\n",
    "\n",
    "selector = RFE(estimator=modelo , n_features_to_select= 107)\n",
    "selector.fit(X,y)\n",
    "print(selector.ranking_)\n",
    "columnasfinales = X.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        0      1        2    3    4       5       6      7       8      9    \\\n0      20.0   80.0  11622.0  5.0  6.0  1961.0  1961.0    0.0   468.0  144.0   \n1      20.0   81.0  14267.0  6.0  6.0  1958.0  1958.0  108.0   923.0    0.0   \n2      60.0   74.0  13830.0  5.0  5.0  1997.0  1998.0    0.0   791.0    0.0   \n3      60.0   78.0   9978.0  6.0  6.0  1998.0  1998.0   20.0   602.0    0.0   \n4     120.0   43.0   5005.0  8.0  5.0  1992.0  1992.0    0.0   263.0    0.0   \n...     ...    ...      ...  ...  ...     ...     ...    ...     ...    ...   \n1454  160.0   21.0   1936.0  4.0  7.0  1970.0  1970.0    0.0     0.0    0.0   \n1455  160.0   21.0   1894.0  4.0  5.0  1970.0  1970.0    0.0   252.0    0.0   \n1456   20.0  160.0  20000.0  5.0  7.0  1960.0  1996.0    0.0  1224.0    0.0   \n1457   85.0   62.0  10441.0  5.0  5.0  1992.0  1992.0    0.0   337.0    0.0   \n1458   60.0   74.0   9627.0  7.0  5.0  1993.0  1994.0   94.0   758.0    0.0   \n\n      ...  155  156  157  158  159  160  161  162  163  164  \n0     ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n1     ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n2     ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n3     ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n4     ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n1454  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n1455  ...  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n1456  ...  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n1457  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n1458  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n\n[1459 rows x 165 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>155</th>\n      <th>156</th>\n      <th>157</th>\n      <th>158</th>\n      <th>159</th>\n      <th>160</th>\n      <th>161</th>\n      <th>162</th>\n      <th>163</th>\n      <th>164</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20.0</td>\n      <td>80.0</td>\n      <td>11622.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>1961.0</td>\n      <td>1961.0</td>\n      <td>0.0</td>\n      <td>468.0</td>\n      <td>144.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.0</td>\n      <td>81.0</td>\n      <td>14267.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>1958.0</td>\n      <td>1958.0</td>\n      <td>108.0</td>\n      <td>923.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60.0</td>\n      <td>74.0</td>\n      <td>13830.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>1997.0</td>\n      <td>1998.0</td>\n      <td>0.0</td>\n      <td>791.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60.0</td>\n      <td>78.0</td>\n      <td>9978.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>1998.0</td>\n      <td>1998.0</td>\n      <td>20.0</td>\n      <td>602.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>120.0</td>\n      <td>43.0</td>\n      <td>5005.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>1992.0</td>\n      <td>1992.0</td>\n      <td>0.0</td>\n      <td>263.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>160.0</td>\n      <td>21.0</td>\n      <td>1936.0</td>\n      <td>4.0</td>\n      <td>7.0</td>\n      <td>1970.0</td>\n      <td>1970.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>160.0</td>\n      <td>21.0</td>\n      <td>1894.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>1970.0</td>\n      <td>1970.0</td>\n      <td>0.0</td>\n      <td>252.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>20.0</td>\n      <td>160.0</td>\n      <td>20000.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>1960.0</td>\n      <td>1996.0</td>\n      <td>0.0</td>\n      <td>1224.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>85.0</td>\n      <td>62.0</td>\n      <td>10441.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>1992.0</td>\n      <td>1992.0</td>\n      <td>0.0</td>\n      <td>337.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>60.0</td>\n      <td>74.0</td>\n      <td>9627.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>1993.0</td>\n      <td>1994.0</td>\n      <td>94.0</td>\n      <td>758.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1459 rows × 165 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in X.columns:\n",
    "    \n",
    "#     X[column] = X[column]/X[column].max()\n",
    "    \n",
    "#     divisor2 = X_test_final[column].max()\n",
    "    \n",
    "#     if divisor2 == 0:\n",
    "        \n",
    "#         divisor2 = 1\n",
    "    \n",
    "#     X_test_final[column] = X_test_final[column]/divisor2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'columnasfinales' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-22966870a37f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumnasfinales\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumnasfinales\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'columnasfinales' is not defined"
     ]
    }
   ],
   "source": [
    "X = X[columnasfinales]\n",
    "X_test_final = X_test_final[columnasfinales]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'N_est 550/ Cv 5/ Learning_rate 0.0495/ Maxdepth:2/ Colsample:0.3/ Subsample: 0.6': 15444.614051797946,\n 'N_est 550/ Cv 5/ Learning_rate 0.0495/ Maxdepth:4/ Colsample:0.3/ Subsample: 0.6': 15444.614051797946}"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def CrossVal (n_estimators, cv, learning_rate, X, y, max_depth, colsample_bytree,subsample):\n",
    "    \n",
    "   #Define the model\n",
    "    \n",
    "    my_model = XGBRegressor(objective='reg:squarederror', eval_metric='mae', random_state=0, \n",
    "    n_estimators= n_estimators, learning_rate = learning_rate, n_jobs=2, colsample_bytree=colsample_bytree, subsample=subsample, verbosity=1) # Your code here\n",
    "    \n",
    "    MAE = -1 * cross_val_score(my_model, X, y, cv=cv, scoring='neg_mean_absolute_error') #Acá pongo X e y enteras porque estoy en la funcion de crossvalidation. SOLITA va a tomar una parte para test y otra para train.\n",
    "    \n",
    "    prom_MAE = MAE.mean()\n",
    "    \n",
    "    return prom_MAE\n",
    "\n",
    "results = {}\n",
    "\n",
    "for estimators in [550]:\n",
    "    for cv in [5]:\n",
    "        for learning in [0.0495]:\n",
    "            for maxdepth in [2,4]:\n",
    "                for colsample in [0.3]:\n",
    "                    for subsample in [0.6]:\n",
    "            \n",
    "                        results[\"N_est \"+str(estimators)+\"/ Cv \"+str(cv)+\"/ Learning_rate \"+str(learning)+ \"/ Maxdepth:\" + str(maxdepth) + \"/ Colsample:\" +str(colsample) + \"/ Subsample: \" + str(subsample)  ] = CrossVal(estimators,cv,learning, X, y, maxdepth, colsample , subsample)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.3, eval_metric='mae',\n             gamma=0, gpu_id=-1, importance_type='gain',\n             interaction_constraints='', learning_rate=0.0495, max_delta_step=0,\n             max_depth=6, min_child_weight=1, missing=nan,\n             monotone_constraints='()', n_estimators=550, n_jobs=2,\n             num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n             scale_pos_weight=1, subsample=0.6, tree_method='exact',\n             validate_parameters=1, verbosity=1)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "modelo = XGBRegressor(objective='reg:squarederror', eval_metric='mae', random_state=0, \n",
    "    n_estimators= 550, learning_rate = 0.0495, n_jobs=2, colsample_bytree=0.3, subsample=0.6, verbosity=1)# Your code here\n",
    "\n",
    "#Fit the model\n",
    "modelo.fit(X, y, verbose=False) #Armo el modelo con toda la data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = modelo.predict(X_test_final)\n",
    "\n",
    "\n",
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': X_test.index, #Importante que sea el del X_test original pq tiene el index original.\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('XGBSubmission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('agusentorno': conda)",
   "language": "python",
   "name": "python37964bitagusentornoconda51664e877804487aa3da8880320029cb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}